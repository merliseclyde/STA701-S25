[
  {
    "objectID": "abstracts/kat_huzar.html",
    "href": "abstracts/kat_huzar.html",
    "title": "Rerandomization with missing data",
    "section": "",
    "text": "Randomized control trials are considered the gold standard in research because they allow for high confidence in establishing cause-and-effect relationships. Randomly assigning participants to the treatment or control group ensures that any observed differences in outcomes between these groups can be attributed to the intervention rather than external factors. However, differences between the groups can still occur due to chance, potentially resulting in misleading results. The issue of imbalance on observed covariates can be addressed in the design phase: rerandomization selects a treatment assignment from a subset of assignments that satisfy a predetermined balance criterion for pre-treatment covariates. Under rerandomization, classical estimators yield a more precise estimator and combining rerandomization with the regression adjustment can further improve inference. In practice, even in the pre-treatment stage, there may be substantial missingness in the data, which in turn can reduce the improvements due to rerandomization which cannot be addressed by simple post-hoc regression adjustment. By introducing missing data imputation methods into the rerandomization, we are able to recover the efficiency losses for estimating average treatment effects. We also show how performing rerandomization that adjusts for missingness combined with regression adjustment increases the precision of the estimates compared to regression adjustment alone, and recommends the use of rerandomization in the design of the study when missing data are present.\n\n\nMy advisor is Alex Volfovsky\n\n\n\nKat is a third year student interested in designing experiments that improve covariate balance and better the efficiency of causal estimates."
  },
  {
    "objectID": "abstracts/kat_huzar.html#abstract",
    "href": "abstracts/kat_huzar.html#abstract",
    "title": "Rerandomization with missing data",
    "section": "",
    "text": "Randomized control trials are considered the gold standard in research because they allow for high confidence in establishing cause-and-effect relationships. Randomly assigning participants to the treatment or control group ensures that any observed differences in outcomes between these groups can be attributed to the intervention rather than external factors. However, differences between the groups can still occur due to chance, potentially resulting in misleading results. The issue of imbalance on observed covariates can be addressed in the design phase: rerandomization selects a treatment assignment from a subset of assignments that satisfy a predetermined balance criterion for pre-treatment covariates. Under rerandomization, classical estimators yield a more precise estimator and combining rerandomization with the regression adjustment can further improve inference. In practice, even in the pre-treatment stage, there may be substantial missingness in the data, which in turn can reduce the improvements due to rerandomization which cannot be addressed by simple post-hoc regression adjustment. By introducing missing data imputation methods into the rerandomization, we are able to recover the efficiency losses for estimating average treatment effects. We also show how performing rerandomization that adjusts for missingness combined with regression adjustment increases the precision of the estimates compared to regression adjustment alone, and recommends the use of rerandomization in the design of the study when missing data are present.\n\n\nMy advisor is Alex Volfovsky\n\n\n\nKat is a third year student interested in designing experiments that improve covariate balance and better the efficiency of causal estimates."
  },
  {
    "objectID": "abstracts/lorenzo_mauri.html",
    "href": "abstracts/lorenzo_mauri.html",
    "title": "Spectral decomposition-assisted multi-study factor analysis",
    "section": "",
    "text": "This work focuses on covariance estimation for multi-study data. Popular approaches employ factor-analytic terms with shared and study-specific loadings that decompose the variance into (i) a shared low-rank component, (ii) study-specific low-rank components, and (iii) a diagonal term capturing idiosyncratic variability. Our proposed methodology estimates the latent factors via spectral decompositions and infers the factor loadings via surrogate regression tasks, avoiding identifiability and computational issues of existing alternatives. The approximation error decreases as the sample size and the data dimension diverge, formalizing a blessing of dimensionality. Conditionally on the factors, loadings and residual error variances are inferred via conjugate normal-inverse gamma priors. The conditional posterior distribution of factor loadings has a simple product form across outcomes, facilitating parallelization. We show favorable asymptotic properties, including central limit theorems for point estimators and posterior contraction. The methods are applied to integrate three studies on gene associations among immune cells.\n\n\nDavid B. Dunson\n\n\n\nLorenzo is a third year student working on latent factor models."
  },
  {
    "objectID": "abstracts/lorenzo_mauri.html#abstract",
    "href": "abstracts/lorenzo_mauri.html#abstract",
    "title": "Spectral decomposition-assisted multi-study factor analysis",
    "section": "",
    "text": "This work focuses on covariance estimation for multi-study data. Popular approaches employ factor-analytic terms with shared and study-specific loadings that decompose the variance into (i) a shared low-rank component, (ii) study-specific low-rank components, and (iii) a diagonal term capturing idiosyncratic variability. Our proposed methodology estimates the latent factors via spectral decompositions and infers the factor loadings via surrogate regression tasks, avoiding identifiability and computational issues of existing alternatives. The approximation error decreases as the sample size and the data dimension diverge, formalizing a blessing of dimensionality. Conditionally on the factors, loadings and residual error variances are inferred via conjugate normal-inverse gamma priors. The conditional posterior distribution of factor loadings has a simple product form across outcomes, facilitating parallelization. We show favorable asymptotic properties, including central limit theorems for point estimators and posterior contraction. The methods are applied to integrate three studies on gene associations among immune cells.\n\n\nDavid B. Dunson\n\n\n\nLorenzo is a third year student working on latent factor models."
  },
  {
    "objectID": "abstracts/TBA.html#abstract",
    "href": "abstracts/TBA.html#abstract",
    "title": "701 abstract",
    "section": "Abstract",
    "text": "Abstract\nTBA\n\n\nAdvisor(s)\nProf.\n\n\nBio"
  },
  {
    "objectID": "abstracts/Houjie_Wang.html",
    "href": "abstracts/Houjie_Wang.html",
    "title": "Likelihood-based Inference on Partially Observed Epidemics and Network Dynamics",
    "section": "",
    "text": "Pandemic modeling based on dynamic social contact network has gradually gained popularity and has been proved to be better at parameter estimation than the traditional epidemic models based on the traditional``random mixing assumption’’. However, leveraging the dynamics of the contact network requires very high-resolution data, which is costly to collect and could raise privacy concerns. To relaxed the need for granular observations, we propose a data-augmentation method for an advanced individual-level framework with interplay between the SIR-type epidemics and an underlying dynamic social contact network, which allows the social contact network to be observed at a very low frequency. By repeated simulation of disease transmission in a dynamic social contact network, we show that our method with the coarsened data is able to carry out valid estimation and inference of the infection rate of the pandemic. We applied our method to an actual dataset of on-campus university students suffered from a flu pandemic where granular observations of their epidemic status and dynamic contact network is available, and the result shows that the estimation with the coarsened data is close to the granular data MLE. This verifies the method and shreds light on its application to a larger scale.\n\n\nAlexander Volfovsky\n\n\n\nBS in statistics at Texas A&M University; MS in in statistics at University of Washington. Currently 3rd year in the department. Interested to work on methodologies to address applied modeling problems in network and time series data."
  },
  {
    "objectID": "abstracts/Houjie_Wang.html#abstract",
    "href": "abstracts/Houjie_Wang.html#abstract",
    "title": "Likelihood-based Inference on Partially Observed Epidemics and Network Dynamics",
    "section": "",
    "text": "Pandemic modeling based on dynamic social contact network has gradually gained popularity and has been proved to be better at parameter estimation than the traditional epidemic models based on the traditional``random mixing assumption’’. However, leveraging the dynamics of the contact network requires very high-resolution data, which is costly to collect and could raise privacy concerns. To relaxed the need for granular observations, we propose a data-augmentation method for an advanced individual-level framework with interplay between the SIR-type epidemics and an underlying dynamic social contact network, which allows the social contact network to be observed at a very low frequency. By repeated simulation of disease transmission in a dynamic social contact network, we show that our method with the coarsened data is able to carry out valid estimation and inference of the infection rate of the pandemic. We applied our method to an actual dataset of on-campus university students suffered from a flu pandemic where granular observations of their epidemic status and dynamic contact network is available, and the result shows that the estimation with the coarsened data is close to the granular data MLE. This verifies the method and shreds light on its application to a larger scale.\n\n\nAlexander Volfovsky\n\n\n\nBS in statistics at Texas A&M University; MS in in statistics at University of Washington. Currently 3rd year in the department. Interested to work on methodologies to address applied modeling problems in network and time series data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Graduate Student Research Seminar Series",
    "section": "",
    "text": "Time: Mondays 11:45 - 1:00 pm\nPlace: Old Chem 116\nInstructor: Merlise Clyde clyde@duke.edu"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Graduate Student Research Seminar Series",
    "section": "Schedule ",
    "text": "Schedule \n\n\n\n\n\n\n\n\nDate\nModerator\nSpeaker\nTitle\n\n\n\n\n13 Jan\nFaculty Meeting\n\n\n\n\n\n\n\n\nNo Talks\n\n\n\n\n\n\n20 Jan\nMLK Holiday\n\n\n\n\n\n\n\n\nNo Talks\n\n\n\n\n\n\n27 Jan\nHun Kang\nCathy Lee\nSharp Bounding Null Effects in Causal Experiments with Ordinal Outcomes\n\n\n\n\n\n\nHoujie Wang\nLikelihood-based Inference on Partially Observed Epidemics and Network Dynamics\n\n\n3 Feb\nFaculty Meeting\n\n\n\n\n\n\n\n\nNo Talks\n\n\n\n\n\n\n10 Feb\nSylvia Vincent\nBonjung Sung\nTesting Separability of Covariance Matrices in High-Dimensional Settings\n\n\n\n\n\n\nKateryna \"Kat\" Husar\nRerandomization with Missing Data\n\n\n17 Feb\nJoshua Lim\nLuke Vrotsos\nDynamic graphical models: Theory, structure and counterfactual forecasting\n\n\n\n\n\n\n\n\n\n\n\n\n24 Feb\nSerim Hong\nBraden Scherting\nTBA\n\n\n\n\n\n\nLorenzo Mauri\nSpectral decomposition-assisted multi-study factor analysis\n\n\n3 Mar\nFaculty Meeting\n\n\n\n\n\n\n\n\nNo Talks\n\n\n\n\n\n\n10 Mar\nSpring Break\n\n\n\n\n\n\n\n\nNo Talks\n\n\n\n\n\n\n17 Mar\nLuigi Malgieri\nAihua Li\n\n\n\n\n\n\n\n\nYen-Chun Liu\n\n\n\n\n24 Mar\nEmily Jensen\nPiotr Suder\n\n\n\n\n\n\n\n\nBennedetta Bruni\n\n\n\n\n31 Mar\nYinyihong Liu\nSuchismita Roy\n\n\n\n\n\n\n\n\nLeah Johnson\n\n\n\n\n7 Apr\nFaculty Meeting\n\n\n\n\n\n\n\n\nNo Talks\n\n\n\n\n\n\n14 Apr\nRuwimal Pathiraja\nCaitrin Murphy\n\n\n\n\n\n\n\n\nYueqi Guo\n\n\n\n\n21 Apr\nReading Period"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This course provides graduate students with the opportunity to share their research with other students and faculty, as well as practice giving good research presentations. Each session will consist of either two short presentations or one long presentation. Presenters will receive constructive feedback from both myself and the audience, on both the presentation and research content. Students are encouraged (and expected) to contribute to discussions - this helps both the presenter and your own research!"
  },
  {
    "objectID": "about.html#description",
    "href": "about.html#description",
    "title": "About",
    "section": "",
    "text": "This course provides graduate students with the opportunity to share their research with other students and faculty, as well as practice giving good research presentations. Each session will consist of either two short presentations or one long presentation. Presenters will receive constructive feedback from both myself and the audience, on both the presentation and research content. Students are encouraged (and expected) to contribute to discussions - this helps both the presenter and your own research!"
  },
  {
    "objectID": "about.html#logistics",
    "href": "about.html#logistics",
    "title": "About",
    "section": "Logistics",
    "text": "Logistics\n\nSpeakers are expected to present in-person. A Zoom link will be available only for students who cannot physically attend or external audience members.\nStudents presenting will invite their PhD advisors and committee members to attend.\nAll PhD students in Statistical Science are recommended to register for STA 701S each semester, and all PhD students in Statistical Science in Years 3+ of studies will be required to register and present in STA 701S each year.\nThere will be two talks scheduled in each class. Each talk should be no longer than 25 minutes, which leaves ample time for questions & suggestions from the audience.\nFirst and second year PhD students will serve as Moderators, who will introduce the speakers and facilitate Q&A.\nAny students who will need to change the date of the presentation should submit a request in Github.1 Please provide the alternate date(s) and confirmation that the other individual is willing to switch.\nPlease submit titles and abstracts at least one week in advance."
  },
  {
    "objectID": "about.html#footnotes",
    "href": "about.html#footnotes",
    "title": "About",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou must be logged in to GitHub to submit a request.↩︎"
  },
  {
    "objectID": "abstracts/houjie_wang.html",
    "href": "abstracts/houjie_wang.html",
    "title": "Likelihood-based Inference on Partially Observed Epidemics and Network Dynamics",
    "section": "",
    "text": "Pandemic modeling based on dynamic social contact network has gradually gained popularity and has been proved to be better at parameter estimation than the traditional epidemic models based on the traditional``random mixing assumption’’. However, leveraging the dynamics of the contact network requires very high-resolution data, which is costly to collect and could raise privacy concerns. To relaxed the need for granular observations, we propose a data-augmentation method for an advanced individual-level framework with interplay between the SIR-type epidemics and an underlying dynamic social contact network, which allows the social contact network to be observed at a very low frequency. By repeated simulation of disease transmission in a dynamic social contact network, we show that our method with the coarsened data is able to carry out valid estimation and inference of the infection rate of the pandemic. We applied our method to an actual dataset of on-campus university students suffered from a flu pandemic where granular observations of their epidemic status and dynamic contact network is available, and the result shows that the estimation with the coarsened data is close to the granular data MLE. This verifies the method and shreds light on its application to a larger scale.\n\n\nAlexander Volfovsky\n\n\n\nBS in statistics at Texas A&M University; MS in in statistics at University of Washington. Currently 3rd year in the department. Interested to work on methodologies to address applied modeling problems in network and time series data."
  },
  {
    "objectID": "abstracts/houjie_wang.html#abstract",
    "href": "abstracts/houjie_wang.html#abstract",
    "title": "Likelihood-based Inference on Partially Observed Epidemics and Network Dynamics",
    "section": "",
    "text": "Pandemic modeling based on dynamic social contact network has gradually gained popularity and has been proved to be better at parameter estimation than the traditional epidemic models based on the traditional``random mixing assumption’’. However, leveraging the dynamics of the contact network requires very high-resolution data, which is costly to collect and could raise privacy concerns. To relaxed the need for granular observations, we propose a data-augmentation method for an advanced individual-level framework with interplay between the SIR-type epidemics and an underlying dynamic social contact network, which allows the social contact network to be observed at a very low frequency. By repeated simulation of disease transmission in a dynamic social contact network, we show that our method with the coarsened data is able to carry out valid estimation and inference of the infection rate of the pandemic. We applied our method to an actual dataset of on-campus university students suffered from a flu pandemic where granular observations of their epidemic status and dynamic contact network is available, and the result shows that the estimation with the coarsened data is close to the granular data MLE. This verifies the method and shreds light on its application to a larger scale.\n\n\nAlexander Volfovsky\n\n\n\nBS in statistics at Texas A&M University; MS in in statistics at University of Washington. Currently 3rd year in the department. Interested to work on methodologies to address applied modeling problems in network and time series data."
  },
  {
    "objectID": "abstracts/cathy_lee.html",
    "href": "abstracts/cathy_lee.html",
    "title": "Sharp Bounding Null Effects in Causal Experiments with Ordinal Outcomes",
    "section": "",
    "text": "Ordinal outcomes are commonly measured across disciplines. However, with such ordered categorical outcomes, we do not have information on the magnitude of the difference between outcomes. Because of this, commonly studied estimands in causal experiments, such as the average treatment effect (ATE), are not well defined. One approach to dealing with ordinal outcomes is latent variable modeling. However, a partial identification strategy may be desirable as it does not require making modeling assumptions. To that end, we prove sharp upper and lower bounds on the probability that the potential outcome under treatment is equal to that under control. The infrequency at which the sharp lower bound is strictly greater than zero motivates us to prove how the sharp lower bound changes when we inject belief on the magnitude of the probability that the outcome under the two groups are equal.\n\n\nAlex Volfovsky\n\n\n\nCathy is a 4th year whose research focus is in causal inference."
  },
  {
    "objectID": "abstracts/cathy_lee.html#abstract",
    "href": "abstracts/cathy_lee.html#abstract",
    "title": "Sharp Bounding Null Effects in Causal Experiments with Ordinal Outcomes",
    "section": "",
    "text": "Ordinal outcomes are commonly measured across disciplines. However, with such ordered categorical outcomes, we do not have information on the magnitude of the difference between outcomes. Because of this, commonly studied estimands in causal experiments, such as the average treatment effect (ATE), are not well defined. One approach to dealing with ordinal outcomes is latent variable modeling. However, a partial identification strategy may be desirable as it does not require making modeling assumptions. To that end, we prove sharp upper and lower bounds on the probability that the potential outcome under treatment is equal to that under control. The infrequency at which the sharp lower bound is strictly greater than zero motivates us to prove how the sharp lower bound changes when we inject belief on the magnitude of the probability that the outcome under the two groups are equal.\n\n\nAlex Volfovsky\n\n\n\nCathy is a 4th year whose research focus is in causal inference."
  },
  {
    "objectID": "abstracts/luke_vrotsos.html",
    "href": "abstracts/luke_vrotsos.html",
    "title": "Dynamic graphical models: Theory, structure and counterfactual forecasting",
    "section": "",
    "text": "Simultaneous graphical dynamic linear models (SGDLMs) provide advances in flexibility, parsimony and scalability of multivariate time series analysis, with proven utility in forecasting. Core theoretical aspects of such models are developed, including new results linking dynamic graphical and latent factor models. Methodological developments extend existing Bayesian sequential analyses for counterfactual forecasting. The latter, involving new Bayesian computational developments for missing data in SGDLMs, is motivated by causal applications. A detailed example illustrating the models and new methodology concerns global macroeconomic time series with complex, time-varying cross-series relationships and primary interests in potential causal effects.\nSlides\n\n\nMike West\n\n\n\nLuke is a third-year PhD student in the Department of Statistical Science working with Mike West on Bayesian time series models."
  },
  {
    "objectID": "abstracts/luke_vrotsos.html#abstract",
    "href": "abstracts/luke_vrotsos.html#abstract",
    "title": "Dynamic graphical models: Theory, structure and counterfactual forecasting",
    "section": "",
    "text": "Simultaneous graphical dynamic linear models (SGDLMs) provide advances in flexibility, parsimony and scalability of multivariate time series analysis, with proven utility in forecasting. Core theoretical aspects of such models are developed, including new results linking dynamic graphical and latent factor models. Methodological developments extend existing Bayesian sequential analyses for counterfactual forecasting. The latter, involving new Bayesian computational developments for missing data in SGDLMs, is motivated by causal applications. A detailed example illustrating the models and new methodology concerns global macroeconomic time series with complex, time-varying cross-series relationships and primary interests in potential causal effects.\nSlides\n\n\nMike West\n\n\n\nLuke is a third-year PhD student in the Department of Statistical Science working with Mike West on Bayesian time series models."
  },
  {
    "objectID": "abstracts/bongjung_sung.html",
    "href": "abstracts/bongjung_sung.html",
    "title": "Testing Separability of Covariance Matrices in High-Dimensional Settings",
    "section": "",
    "text": "Due to their parsimony, separable covariance models have been popular in modeling matrix-variate data. Yet, they may yield misleading inferences if the separability assumption is incorrect. Likelihood ratio tests have tractable null distributions and good power when the sample size n is at least the number of variables p, but are not well-defined otherwise. Other existing separability tests for the p&gt;n case have low power for small sample sizes and null distributions dependent on unknown parameters, preventing exact error rate control. To address these issues, we propose novel invariant tests using the core covariance matrix, a complementary notion to a separable covariance matrix. We show that testing separability of a covariance matrix is equivalent to testing sphericity of its core component. Based on this, we construct the test statistics that are well-defined in high-dimensional settings and have distributions that are invariant under the null of separability, allowing exact simulation of null distributions. We study asymptotic null distributions and show consistency of our tests when p/n→ϒ∈(0,∞). The large power of our proposed tests compared to existing procedures is also numerically illustrated.\n\n\nPeter Hoff\n\n\n\nBongjung is a third year PhD student interested in the statistical application with a core covariance matrix."
  },
  {
    "objectID": "abstracts/bongjung_sung.html#abstract",
    "href": "abstracts/bongjung_sung.html#abstract",
    "title": "Testing Separability of Covariance Matrices in High-Dimensional Settings",
    "section": "",
    "text": "Due to their parsimony, separable covariance models have been popular in modeling matrix-variate data. Yet, they may yield misleading inferences if the separability assumption is incorrect. Likelihood ratio tests have tractable null distributions and good power when the sample size n is at least the number of variables p, but are not well-defined otherwise. Other existing separability tests for the p&gt;n case have low power for small sample sizes and null distributions dependent on unknown parameters, preventing exact error rate control. To address these issues, we propose novel invariant tests using the core covariance matrix, a complementary notion to a separable covariance matrix. We show that testing separability of a covariance matrix is equivalent to testing sphericity of its core component. Based on this, we construct the test statistics that are well-defined in high-dimensional settings and have distributions that are invariant under the null of separability, allowing exact simulation of null distributions. We study asymptotic null distributions and show consistency of our tests when p/n→ϒ∈(0,∞). The large power of our proposed tests compared to existing procedures is also numerically illustrated.\n\n\nPeter Hoff\n\n\n\nBongjung is a third year PhD student interested in the statistical application with a core covariance matrix."
  }
]